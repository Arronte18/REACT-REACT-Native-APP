{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd86fda",
   "metadata": {},
   "source": [
    "Prepare Restaurant Data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2168ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id                                              alias  \\\n",
      "0  M1cIV-JrVOxMjG_K6bUeiw                         craft-and-common-orlando-2   \n",
      "1  WulVBxLRw4mwn4yjG4JkyQ                           kres-chophouse-orlando-2   \n",
      "2  wD_LRs35rEldm95MtTdKJw                    tin-and-taco-downtown-orlando-3   \n",
      "3  7HDwsoFVZwj9llu5QOwtEw  super-rico-colombian-restaurant-and-bar-orlando-2   \n",
      "4  BAle9XGF4_x-uHAQi59qCw                      the-greenery-creamery-orlando   \n",
      "\n",
      "                                    name  \\\n",
      "0                         Craft & Common   \n",
      "1                         Kres Chophouse   \n",
      "2                  Tin & Taco - Downtown   \n",
      "3  Super Rico Colombian Restaurant & Bar   \n",
      "4                  The Greenery Creamery   \n",
      "\n",
      "                                           image_url  is_closed  \\\n",
      "0  https://s3-media3.fl.yelpcdn.com/bphoto/oVW03A...      False   \n",
      "1  https://s3-media2.fl.yelpcdn.com/bphoto/HhDNvu...      False   \n",
      "2  https://s3-media4.fl.yelpcdn.com/bphoto/wXve51...      False   \n",
      "3  https://s3-media4.fl.yelpcdn.com/bphoto/f2neje...      False   \n",
      "4  https://s3-media1.fl.yelpcdn.com/bphoto/XKYeuW...      False   \n",
      "\n",
      "                                                 url  review_count  \\\n",
      "0  https://www.yelp.com/biz/craft-and-common-orla...           568   \n",
      "1  https://www.yelp.com/biz/kres-chophouse-orland...           897   \n",
      "2  https://www.yelp.com/biz/tin-and-taco-downtown...           757   \n",
      "3  https://www.yelp.com/biz/super-rico-colombian-...           517   \n",
      "4  https://www.yelp.com/biz/the-greenery-creamery...           494   \n",
      "\n",
      "                          categories  rating  \\\n",
      "0  [coffee, breakfast_brunch, cafes]     4.5   \n",
      "1     [steak, cocktailbars, seafood]     4.5   \n",
      "2       [tacos, beerbar, newmexican]     4.5   \n",
      "3    [colombian, burgers, juicebars]     4.5   \n",
      "4        [desserts, icecream, vegan]     4.5   \n",
      "\n",
      "                                         coordinates        transactions  \\\n",
      "0     {'latitude': 28.54596, 'longitude': -81.37797}  [delivery, pickup]   \n",
      "1  {'latitude': 28.5406819, 'longitude': -81.3794...          [delivery]   \n",
      "2  {'latitude': 28.54345886545256, 'longitude': -...          [delivery]   \n",
      "3  {'latitude': 28.5422483, 'longitude': -81.3802...          [delivery]   \n",
      "4     {'latitude': 28.54012, 'longitude': -81.37198}          [delivery]   \n",
      "\n",
      "  price                                           location         phone  \\\n",
      "0    $$  {'address1': '47 E Robinson St', 'address2': '...  +14077238078   \n",
      "1   $$$  {'address1': '17 W Church St', 'address2': Non...  +14074477950   \n",
      "2    $$  {'address1': '40 W Washington St', 'address2':...  +14074254340   \n",
      "3    $$  {'address1': '57 W Central Blvd', 'address2': ...  +14074267007   \n",
      "4     $  {'address1': '420 E Church St', 'address2': 'U...  +14072861084   \n",
      "\n",
      "    display_phone    distance  \n",
      "0  (407) 723-8078  219.155812  \n",
      "1  (407) 447-7950  398.087848  \n",
      "2  (407) 425-4340  227.780614  \n",
      "3  (407) 426-7007  307.498604  \n",
      "4  (407) 286-1084  698.991997  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSON file\n",
    "restaurants = pd.read_json('restaurants.json')\n",
    "\n",
    "# Define a function to extract the 'alias' values from a list of categories\n",
    "def extract_aliases(categories):\n",
    "    return [category['alias'] for category in categories]\n",
    "\n",
    "# Apply the function to the 'categories' column and store the result in a new column called 'category_aliases'\n",
    "restaurants['categories'] = restaurants['categories'].apply(lambda x: extract_aliases(x))\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "print(restaurants.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5c2de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id  review_count                         categories  \\\n",
      "0  M1cIV-JrVOxMjG_K6bUeiw           568  [coffee, breakfast_brunch, cafes]   \n",
      "1  WulVBxLRw4mwn4yjG4JkyQ           897     [steak, cocktailbars, seafood]   \n",
      "2  wD_LRs35rEldm95MtTdKJw           757       [tacos, beerbar, newmexican]   \n",
      "3  7HDwsoFVZwj9llu5QOwtEw           517    [colombian, burgers, juicebars]   \n",
      "4  BAle9XGF4_x-uHAQi59qCw           494        [desserts, icecream, vegan]   \n",
      "\n",
      "   rating                                        coordinates  \\\n",
      "0     4.5     {'latitude': 28.54596, 'longitude': -81.37797}   \n",
      "1     4.5  {'latitude': 28.5406819, 'longitude': -81.3794...   \n",
      "2     4.5  {'latitude': 28.54345886545256, 'longitude': -...   \n",
      "3     4.5  {'latitude': 28.5422483, 'longitude': -81.3802...   \n",
      "4     4.5     {'latitude': 28.54012, 'longitude': -81.37198}   \n",
      "\n",
      "         transactions price  \n",
      "0  [delivery, pickup]    $$  \n",
      "1          [delivery]   $$$  \n",
      "2          [delivery]    $$  \n",
      "3          [delivery]    $$  \n",
      "4          [delivery]     $  \n",
      "id               object\n",
      "review_count      int64\n",
      "categories       object\n",
      "rating          float64\n",
      "coordinates      object\n",
      "transactions     object\n",
      "price            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "restaurants.drop('alias', axis=1, inplace=True)\n",
    "restaurants.drop('name', axis=1, inplace=True)\n",
    "restaurants.drop('image_url', axis=1, inplace=True)\n",
    "restaurants.drop('url', axis=1, inplace=True)\n",
    "restaurants.drop('phone', axis=1, inplace=True)\n",
    "restaurants.drop('location', axis=1, inplace=True)\n",
    "restaurants.drop('display_phone', axis=1, inplace=True)\n",
    "restaurants.drop('distance', axis=1, inplace=True)\n",
    "restaurants.drop('is_closed', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(restaurants.head())\n",
    "print(restaurants.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da50240",
   "metadata": {},
   "source": [
    "Prepare Reviews for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceab75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            restaurant_id  review_rating                 user_id\n",
      "0  M1cIV-JrVOxMjG_K6bUeiw              5  _PrAKxHQY3BsIE_vGnLOdw\n",
      "1  M1cIV-JrVOxMjG_K6bUeiw              4  6iJroP8frO-EEjjA9p9rjQ\n",
      "2  M1cIV-JrVOxMjG_K6bUeiw              4  9lkKGcEQavs2sXS0upwhLg\n",
      "3  M1cIV-JrVOxMjG_K6bUeiw              5  _PrAKxHQY3BsIE_vGnLOdw\n",
      "4  M1cIV-JrVOxMjG_K6bUeiw              4  6iJroP8frO-EEjjA9p9rjQ\n",
      "restaurant_id    object\n",
      "review_rating     int64\n",
      "user_id          object\n",
      "dtype: object\n",
      "(8798, 3)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data into a Python dictionary\n",
    "with open('reviews.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "rev = []\n",
    "\n",
    "# Iterate through each restaurant ID and its reviews\n",
    "for rest_id, rest_reviews in data.items():\n",
    "    # Iterate through each review for the restaurant\n",
    "    for review in rest_reviews:\n",
    "        # Extract the relevant fields from the review\n",
    "        review_data = {\n",
    "            'restaurant_id': rest_id,\n",
    "            'review_rating': review['rating'],\n",
    "            'user_id': review['user']['id'],\n",
    "        }\n",
    "        # Append the review data to the list\n",
    "        rev.append(review_data)\n",
    "\n",
    "# Convert the list of reviews to a pandas DataFrame\n",
    "reviews = pd.DataFrame(rev)\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "print(reviews.head())\n",
    "\n",
    "print(reviews.dtypes)\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f369cc2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id  review_count  \\\n",
      "1303  jQPML07vnQIxxEs29LG7qg          1084   \n",
      "358   ULdHiY51w7QjVea-mi4mJQ            71   \n",
      "332   tlb4-J-FHUgbRJusYLPfSA            33   \n",
      "860   E-In3GkNpToXr9ISVmUswQ           210   \n",
      "57    96RSYhKtJXU70XmKuhtHeQ           393   \n",
      "1097  GAE73k8sKR9Tm_7CfVKf0Q            43   \n",
      "299   vv9DS3NcbIt-_j78cMN5ug            36   \n",
      "43    WdTLUw0Y-lnGSv-CRnC8Ag           707   \n",
      "1354  fgQaq4AMWZAgzvbWQDOVGA            39   \n",
      "211   wq9TmD0S5eqBmJmA7uDvbw           419   \n",
      "\n",
      "                              categories  rating  \\\n",
      "1303          [seafood, southern, cajun]     3.5   \n",
      "358                     [seafood, cajun]     4.0   \n",
      "332        [southern, seafood, soulfood]     4.0   \n",
      "860        [seafood, cocktailbars, soup]     4.0   \n",
      "57          [seafood, cajun, sandwiches]     4.0   \n",
      "1097  [seafood, foodtrucks, puertorican]     4.0   \n",
      "299     [colombian, hotdogs, foodtrucks]     5.0   \n",
      "43          [cajun, seafood, sandwiches]     4.0   \n",
      "1354   [hotdogs, chicken_wings, seafood]     4.0   \n",
      "211         [dimsum, cantonese, seafood]     3.5   \n",
      "\n",
      "                                            coordinates        transactions  \\\n",
      "1303  {'latitude': 28.4732913, 'longitude': -81.4646...  [delivery, pickup]   \n",
      "358   {'latitude': 28.511930410550764, 'longitude': ...          [delivery]   \n",
      "332    {'latitude': 28.522985, 'longitude': -81.400961}  [pickup, delivery]   \n",
      "860      {'latitude': 28.50335, 'longitude': -81.45807}          [delivery]   \n",
      "57    {'latitude': 28.5529358752087, 'longitude': -8...          [delivery]   \n",
      "1097  {'latitude': 28.5675419, 'longitude': -81.2698...  [delivery, pickup]   \n",
      "299   {'latitude': 28.505554524472792, 'longitude': ...  [delivery, pickup]   \n",
      "43    {'latitude': 28.5574817657471, 'longitude': -8...  [delivery, pickup]   \n",
      "1354  {'latitude': 28.6351795, 'longitude': -81.4147...          [delivery]   \n",
      "211   {'latitude': 28.5536408963856, 'longitude': -8...  [delivery, pickup]   \n",
      "\n",
      "     price  \n",
      "1303    $$  \n",
      "358     $$  \n",
      "332     $$  \n",
      "860     $$  \n",
      "57      $$  \n",
      "1097    $$  \n",
      "299      $  \n",
      "43     $$$  \n",
      "1354     $  \n",
      "211     $$  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mazor/TheFastSupper/data/supper/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define a custom tokenizer function that joins the individual categories within each list\n",
    "def tokenize_categories(categories):\n",
    "    return ','.join(categories)\n",
    "\n",
    "\n",
    "# Define a custom function to transform the price column into a numeric scale\n",
    "def transform_price(price):\n",
    "    if price is None:\n",
    "        return np.nan\n",
    "    elif price == '$':\n",
    "        return 1\n",
    "    elif price == '$$':\n",
    "        return 2\n",
    "    elif price == '$$$':\n",
    "        return 3\n",
    "    elif price == '$$$$':\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "review_pivot = pd.pivot_table(reviews, index='user_id', columns='restaurant_id', values='review_rating')\n",
    "\n",
    "# Create a new DataFrame that includes the transformed price and rating columns\n",
    "restaurants_transformed = restaurants.copy()\n",
    "restaurants_transformed['price_numeric'] = restaurants_transformed['price'].apply(transform_price)\n",
    "restaurants_transformed = restaurants_transformed[['id', 'categories', 'rating', 'price_numeric']]\n",
    "restaurants_transformed = restaurants_transformed.dropna()\n",
    "\n",
    "# Scale the rating and price columns so that they have the same weight as the category column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(restaurants_transformed[['rating', 'price_numeric']])\n",
    "categories_matrix = vectorizer.fit_transform(restaurants_transformed['categories'].apply(tokenize_categories))\n",
    "cosine_similarities = cosine_similarity(categories_matrix)\n",
    "\n",
    "def get_recommendations(restaurants_list, n=10):\n",
    "    # Calculate the cosine similarity between the selected restaurants and all other restaurants\n",
    "    selected_restaurants = restaurants_transformed.loc[restaurants_transformed['id'].isin(restaurants_list)]\n",
    "    selected_categories = selected_restaurants['categories'].apply(tokenize_categories)\n",
    "    selected_categories_matrix = vectorizer.transform(selected_categories)\n",
    "    selected_restaurants_scaled = scaler.transform(selected_restaurants[['rating', 'price_numeric']])\n",
    "    selected_restaurants_full = np.hstack([selected_categories_matrix.toarray(), selected_restaurants_scaled])\n",
    "    cosine_similarities = cosine_similarity(\n",
    "        selected_restaurants_full,\n",
    "        np.hstack([categories_matrix.toarray(), price_scaled, rating_scaled]))\n",
    "\n",
    "    # Find the restaurants with the highest cosine similarity to the selected restaurants\n",
    "    similar_restaurants = pd.Series(cosine_similarities[-1], index=restaurants_transformed.index).sort_values(ascending=False)\n",
    "    top_similar_restaurants = similar_restaurants.head(n+1)[1:]\n",
    "\n",
    "    # Return the full information for the top similar restaurants\n",
    "    return restaurants.loc[top_similar_restaurants.index]\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "recommendations = get_recommendations(['gfM4BLPhZNXDkeWx8jOkvw', 'a__umvCwQmGXsHrLB9Q9FQ'], n=10)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51b446c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Item GFVxe4gtWZwlILWp1qPTLg is not part of the trainset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/TheFastSupper/data/supper/lib/python3.10/site-packages/surprise/trainset.py:155\u001b[0m, in \u001b[0;36mTrainset.to_inner_iid\u001b[0;34m(self, riid)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw2inner_id_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43mriid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GFVxe4gtWZwlILWp1qPTLg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m top_n \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m restaurant_id, rating \u001b[38;5;129;01min\u001b[39;00m new_user\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 25\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mget_neighbors(\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_inner_iid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestaurant_id\u001b[49m\u001b[43m)\u001b[49m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m neighbors:\n\u001b[1;32m     27\u001b[0m         neighbor_id \u001b[38;5;241m=\u001b[39m trainset\u001b[38;5;241m.\u001b[39mto_raw_iid(neighbor)\n",
      "File \u001b[0;32m~/TheFastSupper/data/supper/lib/python3.10/site-packages/surprise/trainset.py:157\u001b[0m, in \u001b[0;36mTrainset.to_inner_iid\u001b[0;34m(self, riid)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw2inner_id_items[riid]\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(riid) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not part of the trainset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Item GFVxe4gtWZwlILWp1qPTLg is not part of the trainset."
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# Convert the user-restaurant matrix to a surprise-compatible format\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(reviews[['user_id', 'restaurant_id', 'review_rating']], reader)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Define the similarity metric and algorithm for the model\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Train the model on the training data\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Create a new user with the user's reviews as the values\n",
    "new_user = {'GFVxe4gtWZwlILWp1qPTLg': 4}\n",
    "\n",
    "# Get the top-n recommended restaurants for the new user\n",
    "top_n = defaultdict(float)\n",
    "for restaurant_id, rating in new_user.items():\n",
    "    neighbors = algo.get_neighbors(trainset.to_inner_iid(restaurant_id), k=10)\n",
    "    for neighbor in neighbors:\n",
    "        neighbor_id = trainset.to_raw_iid(neighbor)\n",
    "        if neighbor_id not in new_user:\n",
    "            prediction = algo.predict(uid='dummy', iid=neighbor_id)\n",
    "            top_n[neighbor_id] += prediction.est\n",
    "\n",
    "# Sort the recommended restaurants by score\n",
    "top_n = sorted(top_n.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the restaurant IDs from the recommendations\n",
    "recommended_restaurants = [restaurant_id for restaurant_id, score in top_n]\n",
    "\n",
    "print(recommended_restaurants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = pd.merge(restaurants, reviews, left_on='id', right_on='restaurant_id')\n",
    "\n",
    "# Merge the restaurant and review data on the restaurant ID and review ID fields\n",
    "data = pd.merge(restaurants, reviews, left_on='id', right_on='restaurant_id')\n",
    "\n",
    "# Select the relevant fields for the model\n",
    "model_data = data[['restaurant_id', 'categories', 'rating']]\n",
    "\n",
    "# Create a new DataFrame with one row for each restaurant-category combination\n",
    "model_data = data.explode('categories')\n",
    "\n",
    "# Check the data type of the 'rating' column\n",
    "print(model_data['rating'].dtype)\n",
    "\n",
    "# Create the user-item matrix\n",
    "user_item_matrix = pd.pivot_table(model_data, index='restaurant_id', columns='categories', values='rating', fill_value=0)\n",
    "\n",
    "# Calculate the cosine similarity between the rows of the matrix\n",
    "item_similarities = cosine_similarity(user_item_matrix)\n",
    "\n",
    "# Select a target user\n",
    "target_user = user_item_matrix.index[0]\n",
    "\n",
    "# Calculate the similarity between the target user and all other users\n",
    "user_similarities = item_similarities_df[target_user].sort_values(ascending=False)\n",
    "\n",
    "# Select the top-k similar users\n",
    "k = 10\n",
    "top_k_users = user_similarities[1:k+1].index\n",
    "\n",
    "# Generate restaurant recommendations for the target user\n",
    "recommendations = user_item_matrix.loc[top_k_users].mean()\n",
    "\n",
    "# Get the top-k recommended restaurants\n",
    "top_k_restaurant_ratings = recommendations.nlargest(k)\n",
    "top_k_restaurants = top_k_restaurant_ratings.index.tolist()\n",
    "\n",
    "# Return the restaurant IDs instead of categories\n",
    "top_k_restaurants_ids = [int(restaurant.split('_')[1]) for restaurant in top_k_restaurants]\n",
    "print(top_k_restaurants_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f66630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
